{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "410BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtsM79dnrscP"
      },
      "source": [
        "# set up the GPU\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "!pip install transformers    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viHYQC_IvSzM"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imOXDwfMwd57"
      },
      "source": [
        "import io\n",
        "import json\n",
        "\n",
        "tweets = []\n",
        "with open('train.jsonl') as train_data:\n",
        "    for i, line in enumerate(train_data):\n",
        "        tweets.append(json.loads(line))\n",
        "print(tweets[0])\n",
        "print(len(tweets))\n",
        "df = pd.DataFrame(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8MS38hKwmiw"
      },
      "source": [
        "import numpy as np\n",
        "df['text'] = df['response']\n",
        "df['label'] = df['label'].apply(lambda x: np.where(df['label'].unique()== x )[0][0])\n",
        "print(df['text'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGOGM3ECzjln"
      },
      "source": [
        "import re \n",
        "def function_clean(text):\n",
        "    text = re.sub(r\"http\\S+\", \"\", text) \n",
        "    text = re.sub(\"@[^\\s]*\", \"\", text)\n",
        "    text = re.sub(\"#[^\\s]*\", \"\", text)\n",
        "    text = re.sub('[0-9]*[+-:]*[0-9]+', '', text)\n",
        "    text = re.sub(\"'s\", \"\", text)\n",
        "    text = re.sub(r\"@USER\", \"\", text) \n",
        "    return text\n",
        "df['text'] = df['text'].apply(lambda text: function_clean(text))\n",
        "df[['text', 'label']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJ8HSKlzru8"
      },
      "source": [
        "# Get the lists of text and their labels.\n",
        "text = df.text.values\n",
        "label = df.label.values\n",
        "print(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyYn9uQL0AU2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqhYxiRO081U"
      },
      "source": [
        "max_len = 0\n",
        "for t in text:\n",
        "    input_ids = tokenizer.encode(t, add_special_tokens = True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max text length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE7wLTmMEjYe"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for t in text:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        t,                      \n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 120,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',    \n",
        "                   )\n",
        "       \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "label = torch.tensor(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7xD0_DvF9AY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_ids, label, test_size = 0.2, random_state = 12)\n",
        "train_masks, validation_masks, _,_ = train_test_split(attention_masks, label,  test_size = 0.2, random_state = 12)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRCU0Jx9HMeI"
      },
      "source": [
        "train_inputs = torch.tensor(X_train)\n",
        "validation_inputs = torch.tensor(X_test)\n",
        "\n",
        "train_labels = torch.tensor(y_train)\n",
        "validation_labels = torch.tensor(y_test)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmnOyD1UL3gW"
      },
      "source": [
        "#create iterator\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "\n",
        "#Create the DataLoader for the training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "#Create the DataLoader for the validation set\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = RandomSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler = validation_sampler, batch_size = batch_size)"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G7p0AzVSKww"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq03dIeoTLFr"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z49oNMDETdfM"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "epochs = 2\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlOMpIKYBmsu"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruv0GcMM56FI"
      },
      "source": [
        "# make prediction suitable to cal flat_f1\n",
        "def logits_to_preds(logits):\n",
        "  preds = []\n",
        "  for i in range(len(logits)):\n",
        "    temp = np.argmax(logits[i], axis =1).flatten()\n",
        "    for j in temp:\n",
        "      preds.append(j)\n",
        "  return preds"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYOnvlOq7Cjh"
      },
      "source": [
        "# make label suitable to cal flat_f1\n",
        "def flatten_label(label):\n",
        "  labels = []\n",
        "  for i in range(len(label)):\n",
        "    for j in label[i]:\n",
        "      labels.append(j)\n",
        "  return labels"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF69Wf0RT5cZ"
      },
      "source": [
        "# Target is for SARCASM\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "def flat_f1(logits_list, true_label_list):\n",
        "  pred_flat = logits_to_preds(logits_list)\n",
        "  labels_flat = flatten_label(true_label_list)\n",
        "  metric_res = precision_recall_fscore_support(labels_flat, pred_flat)\n",
        "  return metric_res"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nArCeIESUWTu"
      },
      "source": [
        "# Training code\n",
        "import random\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    logits_list = []\n",
        "    true_label_list = []\n",
        "    print(\"\")\n",
        "    print('====== Epoch {:} / {:} ======'.format(epoch_i + 1, epochs))\n",
        "    print('training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    #for each batch of training data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "      # Progress update every 100 batches.\n",
        "      if step % 100 == 0 and not step == 0:\n",
        "          # Calculate elapsed time in minutes.\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask,\n",
        "                      labels=b_labels)\n",
        "    \n",
        "      loss = outputs[0]\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1,0)\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      scheduler.step()\n",
        "    \n",
        "    avg_train_loss = total_loss/len(train_dataloader)\n",
        "\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\" Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\" Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    #############validation\n",
        "    print(\"\")\n",
        "    print(\"Running validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "      with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids= None,\n",
        "                        attention_mask = b_input_mask)\n",
        "      \n",
        "      logits = outputs[0]\n",
        "\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      label_ids = b_labels.to('cpu').numpy()\n",
        "      logits_list.append(logits)\n",
        "      true_label_list.append(label_ids)\n",
        "    \n",
        "    # call f1\n",
        "    eval = flat_f1(logits_list, true_label_list)\n",
        "\n",
        "    print(eval)\n",
        "    print(\"  validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZTqdp5C3YVD"
      },
      "source": [
        "print(\"true label: \",  true_label_list[0])\n",
        "print(\"logits:\",  logits_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6CDK9a7fg8N"
      },
      "source": [
        "# Import the test data\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjRgx3kfwfz"
      },
      "source": [
        "import io\n",
        "import json\n",
        "test = []\n",
        "with open('test.jsonl') as fl2:\n",
        "    for i, line in enumerate(fl2):\n",
        "        test.append(json.loads(line))\n",
        "print(len(test))\n",
        "test_df = pd.DataFrame(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqIjL9njg0G5"
      },
      "source": [
        "# do the same data preparation to the test data\n",
        "test_df['text'] = test_df['response']\n",
        "test_df['text'] = test_df['text'].apply(lambda text: function_clean(text))\n",
        "test_text = test_df.text.values"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqfUHjxD_Bc8"
      },
      "source": [
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "for  in test_text:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        t,                      \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 120,           \n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   \n",
        "                        return_tensors = 'pt',    \n",
        "                   )\n",
        "       \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "\n",
        "print('Original: ', test_text[0])\n",
        "print('Token IDs:', test_input_ids[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2XRrbJJHVDe"
      },
      "source": [
        "test_inputs = torch.tensor(test_input_ids)\n",
        "test_masks = torch.tensor(test_attention_masks)\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 16\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxjlamMwIFxK"
      },
      "source": [
        "# prediction on test set\n",
        "\n",
        "print(\"Predicting labels for {:,} test sentences...\".format(len(test_inputs)))\n",
        "\n",
        "model.eval()\n",
        "test_logits_list = []\n",
        "t0 = time.time()\n",
        "\n",
        "# predict\n",
        "for(step, batch) in enumerate(test_dataloader):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      # Progress update every 100 batches.\n",
        "      if step % 100 == 0 and not step == 0:\n",
        "          # Calculate elapsed time in minutes.\n",
        "          elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "          # Report progress.\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "      b_input_ids, b_input_mask = batch\n",
        "      with torch.no_grad():\n",
        "        outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "    \n",
        "      logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      test_logits_list.append(logits)\n",
        "    \n",
        "print(\"   DONE.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiP1YfiELT0i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8a1ce3ee-3d28-44d7-a529-cecf895074bb"
      },
      "source": [
        "# Convert the prediction results to submission format\n",
        "final_predictions = logits_to_preds(test_logits_list)\n",
        "df_pred = pd.DataFrame(data = final_predictions, columns=[\"prediction\"])\n",
        "df_pred[\"twitter\"]= (df_pred.index + 1)\n",
        "df_pred[\"twitter_index\"]= \"twitter_\" + df_pred[\"twitter\"].astype(str)\n",
        "df_pred[\"result\"] = df_pred['prediction'].apply(lambda x: 'SARCASM' if x == 0 else 'NOT_SARCASM')\n",
        "df_pred\n",
        "df_pred[[\"twitter_index\", \"result\"]].to_csv(\"answer.txt\", header=None, index=None, sep=',', mode='w')\n",
        "files.download(\"answer.txt\")"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a7f9b24f-17f1-40df-b861-8b9282b83035\", \"answer.txt\", 39873)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH7hv1E7dUvz"
      },
      "source": [
        "Reference: https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=EKOTlwcmxmej "
      ]
    }
  ]
}